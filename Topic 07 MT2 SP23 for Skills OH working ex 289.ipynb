{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d825be40",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "notebook_header"
    ]
   },
   "source": [
    "# Midterm 2, Spring 2023: Better Reads\n",
    "\n",
    "_Version history:_\n",
    "- 1.0.1 (Sun Apr 2): Corrected typo in Ex. 7 demo\n",
    "- 1.0: Initial release\n",
    "\n",
    "*All of the header information is important. Please read it.*\n",
    "\n",
    "**Topics, number of exercises:** This problem builds on your knowledge of Numpy, pandas, database organization, graph abstractions, and basic Python (for interfacing with other Python libraries). It has **11** exercises, numbered 0 to **10**. There are **21** available points. However, to earn 100% the threshold is **12** points. (Therefore, once you hit **12** points, you can stop. There is no extra credit for exceeding this threshold.)\n",
    "\n",
    "**Free points!** This exam includes one exercise, Exercise 3, whose points are \"**free**.\" However, to get these points you need to read some text and _submit the notebook to the autograder at least once_.\n",
    "\n",
    "**Exercise ordering:** Each exercise builds logically on previous exercises, but you may solve them in any order. Exercises are **not** necessarily ordered by difficulty, but higher point values usually imply more difficult tasks.\n",
    "\n",
    "**Demo cells:** Code cells that start with the comment `### define demo inputs` will load results from prior exercises applied to the entire data set and use those to build demo inputs. These must be run for later demos to work properly but they do not affect the test cells. The data loaded by these cells may be large (at least in terms of human readability). You are free to inspect them, but we did not print them in the starter code.\n",
    "\n",
    "**Debugging you code:** Right before each exercise test cell, there is a block of text explaining the variables available to you for debugging. You may use these to test your code and can print/display them as needed (careful when printing large objects, you may want to print the head or chunks of rows at a time).\n",
    "\n",
    "**Exercise point breakdown:**\n",
    "\n",
    "- Exercise 0: **2** points\n",
    "- Exercise 1: **1** point\n",
    "- Exercise 2: **3** points\n",
    "- Exercise 3: **2** point **FREEBIE! Submit to record them**\n",
    "- Exercise 4: **1** point\n",
    "- Exercise 5: **2** points\n",
    "- Exercise 6: **2** points\n",
    "- Exercise 7: **1** point\n",
    "- Exercise 8: **3** points\n",
    "- Exercise 9: **2** points\n",
    "- Exercise 10: **2** points\n",
    "\n",
    "**Final reminders:** \n",
    "\n",
    "- Submit after **every exercise**\n",
    "- Review the generated grade report after you submit to see what errors were returned\n",
    "- Stay calm, skip problems as needed, and take short breaks at your leisure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6019d2b8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "topic_intro"
    ]
   },
   "source": [
    "# Background: Better Reads #\n",
    "\n",
    "[Goodreads](https://www.goodreads.com/) is a website devoted to curating user-generated book reviews. You'll do some elementary data-mining to uncover \"communities\" of users who like the same books. Such insights might help users find like-minded communities and generate better book recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd80f0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:30:23.592700Z",
     "start_time": "2023-03-29T13:30:23.585568Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Overall workflow.** This notebook has six (6) parts with about 1-3 exercises each.\n",
    "* **Part A:** Analyze user-book interactions [SQL, pandas]\n",
    "* **Part B:** Power-law analysis [pandas, Numpy]\n",
    "* **Part C:** Edge lists, NetworkX, and graph clusters [Python, graphs]\n",
    "* **Part D:** Finding communities via graph clustering [SQL, pandas]\n",
    "* **Part E:** Identifying \"top reads\" by community [pandas]\n",
    "* **Part F:** Merging inventory metadata [pandas]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24f7633",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Getting started (modules) #\n",
    "\n",
    "Skim the code cell below and then run it. Take note of the standard preloaded modules, `numpy as np`, `pandas as pd`, and `sqlite3 as db`, any or all of which you may need to construct your solutions.\n",
    "\n",
    "The other functions are used by our demo and testing code. You can ignore them unless an exercise asks you to do otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18df2454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment in Google Colab\n",
    "# !python --version\n",
    "!pip install dill\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c8b8a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:11.441029Z",
     "start_time": "2023-03-30T22:24:11.074402Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "global_imports"
    ]
   },
   "outputs": [],
   "source": [
    "### Global Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Standard Python modules\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3 as db\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01678447",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Global Imports\n",
    "# Some functionality needed by the notebook and demo cells:\n",
    "from pprint import pprint, pformat\n",
    "import math\n",
    "\n",
    "# === Iteration === #\n",
    "\n",
    "def isiter(x):\n",
    "    \"\"\"\n",
    "    Returns `True` if `x` is iterable.\n",
    "\n",
    "    Uses the \"duck typing\" method described here:\n",
    "    https://stackoverflow.com/questions/1952464/in-python-how-do-i-determine-if-an-object-is-iterable\n",
    "    \"\"\"\n",
    "    try:\n",
    "        iterator = iter(x)\n",
    "    except TypeError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def sample_iter(I, n=1, rng_or_seed=None, replace=False, safe=True):\n",
    "    from pandas import DataFrame\n",
    "    from numpy import ndarray, array\n",
    "    \n",
    "    rng = get_rng(rng_or_seed, ret_type=False)\n",
    "    n_sample = min(n, len(I)) if safe else n\n",
    "    sample_locs = rng.choice(range(len(I)), size=n_sample, replace=replace)\n",
    "    if isinstance(I, DataFrame):\n",
    "        sample = I.iloc[sample_locs]\n",
    "    elif isinstance(I, ndarray) or isinstance(I, list):\n",
    "        sample = I[sample_locs]\n",
    "    elif isinstance(I, dict):\n",
    "        sample_values = list(I.keys())[sample_locs]\n",
    "        sample = {k: I[k] for k in sample_values}\n",
    "    else:\n",
    "        J = array(list(I))\n",
    "        sample = type(I)(J[sample_locs])\n",
    "    return sample\n",
    "\n",
    "# === Messages === #\n",
    "\n",
    "def status_msg(s, verbose=True, **kwargs):\n",
    "    if verbose:\n",
    "        print(s, **kwargs)\n",
    "\n",
    "# === pandas ===\n",
    "\n",
    "def subselect(df, col, values):\n",
    "    \"\"\"\n",
    "    Subselects rows of a `DataFrame` where the column `col`\n",
    "    contains any of the given `values`.\n",
    "\n",
    "    If `values` is a non-iterable object _or_ a `str`,\n",
    "    then this function treats it as a single value to\n",
    "    find.\n",
    "    \"\"\"\n",
    "    if not isinstance(values, str) and isiter(values):\n",
    "        return df[df[col].isin(values)]\n",
    "    return df[df[col] == values]\n",
    "\n",
    "# === Input/output === #\n",
    "\n",
    "# def text_to_file(s, basename, dirname='resource/asnlib/publicdata/', overwrite=True, verbose=True):\n",
    "def text_to_file(s, basename, dirname='', overwrite=True, verbose=True):\n",
    "    from os.path import isfile\n",
    "    filename = f\"{dirname}{basename}\"\n",
    "    status_msg(f\"Writing string to '{filename}'...\", verbose=verbose)\n",
    "    if not overwrite and isfile(filename):\n",
    "        status_msg(f\"  ==> File exists already; skipping.\", verbose=verbose)\n",
    "    else:\n",
    "        with open(filename, \"wt\") as fp:\n",
    "            fp.write(s)\n",
    "        status_msg(f\"  ==> Done!\", verbose=verbose)\n",
    "\n",
    "# def load_text_from_file(basename, dirname='resource/asnlib/publicdata/', abort_on_error=False, verbose=False):\n",
    "def load_text_from_file(basename, dirname='', abort_on_error=False, verbose=False):\n",
    "    from os.path import isfile\n",
    "    filename = f\"{dirname}{basename}\"\n",
    "    status_msg(f\"Loading string from '{filename}'...\", verbose=verbose)\n",
    "    if isfile(filename):\n",
    "        try:\n",
    "            with open(filename, \"rt\") as fp:\n",
    "                s = fp.read()\n",
    "            status_msg(f\"  ==> Done!\", verbose=verbose)\n",
    "        except:\n",
    "            if abort_on_error:\n",
    "                raise\n",
    "            else:\n",
    "                status_msg(f\"  ==> An error occurred.\", verbose=verbose)\n",
    "                s = ''\n",
    "    return s\n",
    "\n",
    "# def df_to_file(df, basename, dirname='resource/asnlib/publicdata/', overwrite=True, verbose=True):\n",
    "def df_to_file(df, basename, dirname='', overwrite=True, verbose=True):\n",
    "    from os.path import isfile\n",
    "    from dill import dumps\n",
    "    filename = f\"{dirname}{basename}\"\n",
    "    if verbose:\n",
    "        print(f\"Writing `DataFrame` to '{filename}'...\")\n",
    "    if not overwrite and isfile(filename):\n",
    "        print(f\"  ==> File exists already; skipping.\")\n",
    "    else:\n",
    "        with open(filename, \"wb\") as fp:\n",
    "            fp.write(dumps(df))\n",
    "        print(f\"  ==> Done!\")\n",
    "\n",
    "# def load_df_from_file(basename, dirname='resource/asnlib/publicdata/', abort_on_error=False, verbose=False):\n",
    "def load_df_from_file(basename, dirname='', abort_on_error=False, verbose=False):\n",
    "    from os.path import isfile\n",
    "    from dill import loads\n",
    "    from pandas import DataFrame\n",
    "    df = DataFrame()\n",
    "    filename = f\"{dirname}{basename}\"\n",
    "    status_msg(f\"Loading `DataFrame` from '{filename}'...\", verbose=verbose)\n",
    "    if isfile(filename):\n",
    "        try:\n",
    "            with open(filename, \"rb\") as fp:\n",
    "                df = loads(fp.read())\n",
    "            status_msg(f\"  ==> Done!\", verbose=verbose)\n",
    "        except:\n",
    "            if abort_on_error:\n",
    "                raise\n",
    "            else:\n",
    "                df = DataFrame()\n",
    "                status_msg(f\"  ==> An error occurred.\", verbose=verbose)\n",
    "    return df\n",
    "\n",
    "# def obj_to_file(df, basename, dirname='resource/asnlib/publicdata/', overwrite=True, verbose=True):\n",
    "def obj_to_file(df, basename, dirname='', overwrite=True, verbose=True):\n",
    "    from os.path import isfile\n",
    "    from dill import dumps\n",
    "    filename = f\"{dirname}{basename}\"\n",
    "    if verbose:\n",
    "        print(f\"Writing object (type `{type(df)}`) to '{filename}'...\")\n",
    "    if not overwrite and isfile(filename):\n",
    "        print(f\"  ==> File exists already; skipping.\")\n",
    "    else:\n",
    "        with open(filename, \"wb\") as fp:\n",
    "            fp.write(dumps(df))\n",
    "        print(f\"  ==> Done!\")\n",
    "\n",
    "# def load_obj_from_file(basename, dirname='resource/asnlib/publicdata/', abort_on_error=False, verbose=False):\n",
    "def load_obj_from_file(basename, dirname='', abort_on_error=False, verbose=False):\n",
    "    from os.path import isfile\n",
    "    from dill import loads\n",
    "    from pandas import DataFrame\n",
    "    filename = f\"{dirname}{basename}\"\n",
    "    status_msg(f\"Loading object from '{filename}'...\", verbose=verbose)\n",
    "    if isfile(filename):\n",
    "        try:\n",
    "            with open(filename, \"rb\") as fp:\n",
    "                df = loads(fp.read())\n",
    "            status_msg(f\"  ==> Done! Type: `{type(df)}`\", verbose=verbose)\n",
    "        except:\n",
    "            if abort_on_error:\n",
    "                raise\n",
    "            else:\n",
    "                df = DataFrame()\n",
    "                status_msg(f\"  ==> An error occurred.\", verbose=verbose)\n",
    "    else:\n",
    "        df = None\n",
    "    return df\n",
    "\n",
    "# def load_table_from_db(table_name, basename, dirname=\"resource/asnlib/publicdata/\", verbose=False):\n",
    "def load_table_from_db(table_name, basename, dirname=\"\", verbose=False):\n",
    "    from sqlite3 import connect\n",
    "    from pandas import read_sql\n",
    "    filename = f\"{dirname}{basename}\"\n",
    "    if verbose:\n",
    "        print(f\"Retrieving table `{table_name}` from SQLite3 DB `{filename}`...\")\n",
    "    conn = connect(f\"file:{filename}?mode=ro\", uri=True)\n",
    "    df = read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "    conn.close()\n",
    "    if verbose:\n",
    "        print(f\"... done! Found {len(df)} rows.\")\n",
    "    return df\n",
    "\n",
    "# ==== RNGs ==== #\n",
    "\n",
    "# https://stackoverflow.com/questions/279561/what-is-the-python-equivalent-of-static-variables-inside-a-function\n",
    "def static_vars(**kwargs):\n",
    "    def decorate(func):\n",
    "        for k in kwargs:\n",
    "            setattr(func, k, kwargs[k])\n",
    "        return func\n",
    "    return decorate\n",
    "\n",
    "@static_vars(DEFAULT_RNG=None)\n",
    "def get_rng(rng_or_seed, ret_type=True):\n",
    "    \"\"\"\n",
    "    Returns a valid pseudorandom-number generator (RNG) object\n",
    "    based on how `rng_or_seed` is set:\n",
    "\n",
    "    - An integer: Creates a new RNG with the integer as a seed\n",
    "    - An existing RNG object: Returns the same object\n",
    "    - `None`: Returns a global \"default\" RNG, which is created\n",
    "      once at module initialization time.\n",
    "\n",
    "    If `ret_type` is set, this function also returns a descriptive\n",
    "    string saying which of the above cases applies. (The intent of\n",
    "    this string is for use in printing as part of debugging output.)\n",
    "    \"\"\"\n",
    "    # Initialize static variable, DEFAULT_RNG\n",
    "    from numpy.random import default_rng\n",
    "    if get_rng.DEFAULT_RNG is None:\n",
    "        get_rng.DEFAULT_RNG = default_rng(1_234_567_890)\n",
    "\n",
    "    if isinstance(rng_or_seed, int):\n",
    "        rng = default_rng(rng_or_seed)\n",
    "        rng_type = f'`default_rng({rng_or_seed})`'\n",
    "    elif rng_or_seed is None:\n",
    "        rng = get_rng.DEFAULT_RNG\n",
    "        rng_type = f'`DEFAULT_RNG` [{rng}]'\n",
    "    else:\n",
    "        rng = rng_or_seed # had better be a RNG\n",
    "        rng_type = f'User-supplied [{rng}]'\n",
    "\n",
    "    return (rng, rng_type) if ret_type else rng\n",
    "\n",
    "# ==== Plotting ==== #\n",
    "def plot_series_loglog(series, ax=None, figsize=(8, 8/16*9), **kwargs):\n",
    "    from matplotlib.pyplot import figure, gca\n",
    "    if ax is None:\n",
    "        fig = figure(figsize=figsize)\n",
    "        ax = gca()\n",
    "    x = series.index\n",
    "    y = series.values\n",
    "    ax.loglog(x, y, '.', **kwargs)\n",
    "    return ax\n",
    "\n",
    "def display_image_from_file(filename, verbose=False):\n",
    "    from IPython.display import Image\n",
    "    if verbose:\n",
    "        print(f\"Loading image, `{filename}` ...\")\n",
    "    display(Image(filename))\n",
    "    if verbose:\n",
    "        print(f\"... done! (Did it appear?)\")\n",
    "\n",
    "# ==== Graph / NetworkX interfacing ===== #\n",
    "\n",
    "def to_nx(edge_list):\n",
    "    from networkx import DiGraph\n",
    "    G = DiGraph()\n",
    "    G.add_weighted_edges_from(edge_list)\n",
    "    return G\n",
    "\n",
    "def graph_to_matrix(G):\n",
    "    try:\n",
    "        from networkx import to_scipy_sparse_array # Works in 3.0\n",
    "        return to_scipy_sparse_array(G)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        from networkx import to_scipy_sparse_matrix # Works in 2.5\n",
    "        return to_scipy_sparse_matrix(G)\n",
    "    except:\n",
    "        raise\n",
    "\n",
    "def graph_spy(G, style='matrix', ax=None, figsize=(6.5, 6.5), **kwargs):\n",
    "    from matplotlib.pyplot import figure, gca\n",
    "    from networkx import spring_layout, draw_networkx_nodes, draw_networkx_edges, draw_networkx_labels\n",
    "    \n",
    "    if ax is None:\n",
    "        fig = figure(figsize=figsize)\n",
    "        ax = gca()\n",
    "        \n",
    "    if style == 'matrix':\n",
    "        A = graph_to_matrix(G)\n",
    "        ax.spy(A, **kwargs)\n",
    "    else:\n",
    "        pos = spring_layout(G, seed=7)\n",
    "\n",
    "        # nodes\n",
    "        draw_networkx_nodes(G, pos) #, node_size=700)\n",
    "\n",
    "        # edges\n",
    "        elarge = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] >= 0.1]\n",
    "        esmall = [(u, v) for (u, v, d) in G.edges(data=True) if d[\"weight\"] < 0.1]\n",
    "        draw_networkx_edges(G, pos, edgelist=elarge, width=2)\n",
    "        draw_networkx_edges(G, pos, edgelist=esmall, width=0.5, alpha=0.5)\n",
    "\n",
    "        # node labels\n",
    "        draw_networkx_labels(G, pos, font_size=10, font_family=\"sans-serif\")\n",
    "        # edge weight labels\n",
    "#        edge_labels = nx.get_edge_attributes(G, \"weight\")\n",
    "#        nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
    "    return ax\n",
    "\n",
    "def detect_communities(G, seed=1_234):\n",
    "    from networkx.algorithms.community import louvain_communities\n",
    "    return louvain_communities(G, seed=seed)\n",
    "\n",
    "def random_clusters(nc, nvc, p_intra=0.5, p_inter=0.1, rng_or_seed=None, verbose=False):\n",
    "    rng = get_rng(rng_or_seed, ret_type=False)\n",
    "    n = nc * nvc\n",
    "    mv_intra = int(p_intra*nvc) + 1 # no. of intra-cluster edges per vertex\n",
    "    mv_inter = int(p_inter*n)       # no. of inter-cluster edges per vertex\n",
    "    \n",
    "    if verbose:\n",
    "        print('Constructing a vertex-clustered graph with these properties:')\n",
    "        print(f'- Number of clusters: nc={nc}')\n",
    "        print(f'- Vertices per cluster: nvc={nvc}')\n",
    "        print(f'- Number of intra-cluster edges per vertex: {mv_intra} (p_intra={p_intra})')\n",
    "        print(f'- Number of inter-cluster edges per vertex: {mv_inter} (p_inter={p_inter})')\n",
    "        print(f'- RNG: {rng}')\n",
    "    \n",
    "    V = set(range(n)) # `n` vertices\n",
    "    E = []\n",
    "    for c in range(nc):\n",
    "        V_c = set(range(c*nvc, (c+1)*nvc))\n",
    "        for v in V_c:\n",
    "            # Add intra-cluster edges for `v`\n",
    "            N_v = sample_iter(V_c - {v}, n=mv_intra, rng_or_seed=rng)\n",
    "            W_v = rng.random(size=len(N_v))\n",
    "            E += [(v, u, w) for u, w in zip(N_v, W_v)]\n",
    "            \n",
    "            # Add inter-cluster edges for `v`\n",
    "            X_v = sample_iter(V - V_c, n=mv_inter, rng_or_seed=rng)\n",
    "            W_v = rng.random(size=len(X_v)) / 10.0 # make these edges weaker, too\n",
    "            E += [(v, u, w) for u, w in zip(X_v, W_v)]\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99924821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/demo_ex2.df\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/demo_ex8.df\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/ex1-user_id.df\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/ex2-log2bin_count.df\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/ex8-input.df\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/goodreads.db\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/tc_2\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/tc_8\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/tc_9\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/ex8-output.df\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/ex8-topreads.df\n",
    "\n",
    "!mkdir tester_fw\n",
    "%cd tester_fw\n",
    "\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/tester_fw/__init__.py\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/tester_fw/test_utils.py\n",
    "!wget https://raw.githubusercontent.com/gt-cse-6040/topic_07_MT2_SP23_289/main/tester_fw/testers.py\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993eb8b7",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "In case it's helpful, here are the versions of Python and standard modules you are using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5972849c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:11.460183Z",
     "start_time": "2023-03-30T22:24:11.442572Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"* Python version: {}\".format(sys.version.replace('\\n', ' ')))\n",
    "print(f\"* Numpy version: {np.__version__}\")\n",
    "print(f\"* pandas version: {pd.__version__}\")\n",
    "print(f\"* sqlite3 version: {db.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbd16b8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## pandas versus SQL ##\n",
    "\n",
    "The actual Goodreads data is provided via a SQLite3 database. However, only some exercises _require_ SQL; most exercises were designed with pandas in mind.\n",
    "\n",
    "Nevertheless, even some of the pandas exercises can be solved using SQL. The cell below defines the function, `dfs_to_conn`, which can be used to create in-memory database connections. If you pass in a dictionary mapping table names to pandas `DataFrame` objects, then `dfs_to_conn` will return a `sqlite3` connection with all of the data in the `DataFrame` objects available under the names given as keys. You are also free to write to the in-memory database by creating tables, inserting, deleting, updating records, etc. Anything that SQLite3 allows should work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45da6d8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**Example:**\n",
    "\n",
    "```python\n",
    "    my_df = pd.DataFrame({'A':[1,2,3], 'B': [4,5,6], 'C':['x', 'y', 'z']})\n",
    "    print(my_df)\n",
    "    #    A  B  C\n",
    "    # 0  1  4  x\n",
    "    # 1  2  5  y\n",
    "    # 2  3  6  z\n",
    "    conn = dfs_to_conn({'my_table': my_df})\n",
    "    cur = conn.cursor()\n",
    "    cur.execute('select A, B, C from my_table')\n",
    "    result = cur.fetchall()\n",
    "    conn.close() \n",
    "    print(result) # list of tuples, each tuple is a row\n",
    "    #[(1, 4, 'x'), (2, 5, 'y'), (3, 6, 'z')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f3479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:11.482085Z",
     "start_time": "2023-03-30T22:24:11.463647Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def dfs_to_conn(conn_dfs, index=False):\n",
    "    import sqlite3\n",
    "    conn = sqlite3.connect(':memory:')\n",
    "    for table_name, df in conn_dfs.items():\n",
    "        df.to_sql(table_name, conn, if_exists='replace', index=index)\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149f9cbe",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Goodreads Data (`grdbconn`) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2226954c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Some of the Goodreads data is stored in a SQLite3 database. The code cell below opens a read-only connection to it named **`grdbconn`**.\n",
    "\n",
    "For now, don't worry about what's there. We will explain any tables you need in the exercises that use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bfb68c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:11.501956Z",
     "start_time": "2023-03-30T22:24:11.483569Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Goodreads database connection:\n",
    "grdbconn = db.connect('file:goodreads.db?mode=ro', uri=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e12f1f4",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Part B: Power laws #\n",
    "\n",
    "> Includes Exercise 2 (3 points).\n",
    "\n",
    "Many types of real-world data have _**power law distributions**_. Roughly speaking, a probability density $f(x)$ is a power law if it behaves like $\\dfrac{1}{x^d}$ for some constant $d$ when $x$ is \"large,\" i.e., as one approaches the tail of the distribution. Let's see if there are any power laws in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c55f7",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "For instance, suppose you have a pandas `Series` that shows, for each user, how many books they interacted with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a9cda4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:21.266041Z",
     "start_time": "2023-03-30T22:24:21.243821Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ux_counts = load_df_from_file(f\"ex1-user_id.df\").set_index('user_id')['count']\n",
    "ux_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ce4b47",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The index is a user ID and the value is an integer count of how many interaction-rows are associated with them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b699cb61",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## **Ex. 2 (3 pts)**: `log2bin_count` ##\n",
    "\n",
    "Given a `Series` object holding values that can range from 1 to $n$, inclusive, we wish to count how many of those integers lie within the _log-two bins_,\n",
    "\n",
    "* $[1, 2)$: that is, starting at one up to but _excluding_ 2;\n",
    "* $[2, 4)$: starting at two up to but _excluding_ 4;\n",
    "* $[4, 8)$: starting at 4 up to but _excluding_ 8;\n",
    "* ...\n",
    "* and $\\left[ 2^{k-1}, 2^k \\right)$: starting at $2^{k-1}$ up to but excluding $2^k$, where $2^k$ is the first power of two greater than $n$.\n",
    "\n",
    "Complete the function,\n",
    "```python\n",
    "def log2bin_count(series):\n",
    "    ...\n",
    "```\n",
    "to compute these counts.\n",
    "\n",
    "**Inputs:** The input `series` is a pandas `Series`-object holding the values.\n",
    "\n",
    "**Your tasks** will involve, most likely, these steps:\n",
    "- Determine what the bins need to be.\n",
    "- Count the number of values in each bin.\n",
    "- Exclude any empty bins, i.e., those with _no_ values.\n",
    "\n",
    "**Outputs:** Your function should return a `DataFrame` with two columns:\n",
    "1. `bin_start`: The value of the left edge of a bin, which are integers starting at 1 and all of the form $2^i$.\n",
    "2. `count`: The number of values in `series` that lie in $\\left[ 2^i, 2^{i+1} \\right)$, also an integer.\n",
    "\n",
    "See the demo below for an example.\n",
    "\n",
    "**Additional notes and hints.**\n",
    "1. You may assume all input values are integers greater than or equal to 1.\n",
    "1. Given a value $x$, the next largest power of two is $2^k$ where $k = \\lceil \\log_2 x \\rceil + 1$.\n",
    "1. A helpful function is [`pandas.cut` (`pd.cut`)](https://pandas.pydata.org/docs/reference/api/pandas.cut.html), but you certainly do not have to use it.\n",
    "1. Recall that you should _omit_ empty bins.\n",
    "\n",
    "**Example/demo:** Suppose the input `Series` looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3f22d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:21.289819Z",
     "start_time": "2023-03-30T22:24:21.267798Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [],
   "source": [
    "### Define demo inputs ###\n",
    "\n",
    "demo_series_ex2 = load_df_from_file('demo_ex2.df').set_index('user_id')['count']\n",
    "display(demo_series_ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca0d36e",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "Then a correct solution would produce:\n",
    "\n",
    "|   bin_start |   count |\n",
    "|------------:|--------:|\n",
    "|          64 |       3 |\n",
    "|         256 |       2 |\n",
    "|         128 |       2 |\n",
    "|          32 |       2 |\n",
    "|          16 |       1 |\n",
    "\n",
    "There is just one input value in $[16, 32)$, namely, the value `49`. But in the bin $[64, 128)$, there are three input values: `76`, `78`, and `119`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc75731",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:21.316308Z",
     "start_time": "2023-03-30T22:24:21.290740Z"
    },
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [],
   "source": [
    "### Exercise 2 solution\n",
    "def log2bin_count(series):\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "### demo function call ###\n",
    "log2bin_count(demo_series_ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc2517",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 2. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa0bca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:21.829191Z",
     "start_time": "2023-03-30T22:24:21.591120Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "ex2",
     "locked": true,
     "points": "3",
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### test_cell_ex2\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_2', \n",
    "    'func': log2bin_count, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'series': {\n",
    "            'dtype': 'series',\n",
    "            'check_modified': True,\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index': 0,\n",
    "            'dtype': 'df',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'jpS7W-CpqAQfuITMEQZL-yVXfhIaCkSaei-emnyRtrI=', path='')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52836447",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**RUN ME:** A correct implementation of `log2bin_count`, when run on `ux_counts` from the full Goodreads dataset, would produce the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d998a817",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:21.849726Z",
     "start_time": "2023-03-30T22:24:21.830317Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ux_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81b9f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:22.299509Z",
     "start_time": "2023-03-30T22:24:21.850818Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ux_counts_log2bins = load_df_from_file('ex2-log2bin_count.df')\n",
    "ax = plot_series_loglog(ux_counts_log2bins.set_index('bin_start')['count'], base=2)\n",
    "ax.set_xlabel('# book interactions (binned)')\n",
    "ax.set_ylabel('fraction of users', rotation=0, horizontalalignment='right')\n",
    "ax.set_title('Are sampled user-book interactions power-law-like?')\n",
    "ax.set_aspect(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57504a74",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "> **Aside (skip if pressed for time):** These interactions do, indeed, appear to follow a power law in the tail of the distribution. In fact, the data in this notebook is a relatively small sample of the full dataset, which consists of hundreds of millions of interactions and has an even longer tail consistent with a power law."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e924468",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## **Ex. 8 (3 pts):** `get_topreads_by_community` ##\n",
    "\n",
    "Suppose we merge the community information into the interactions database. Can we then identify which books each community is \"the most interested in?\" Complete the following function to help answer this question:\n",
    "\n",
    "```python\n",
    "def get_topreads_by_community(xcdf, rank):\n",
    "    ...\n",
    "```\n",
    "\n",
    "**Inputs:** There are two inputs:\n",
    "1. `xcdf` is a `DataFrame` with the following columns:\n",
    "  * `user_id`: A user ID (integer)\n",
    "  * `book_id`: A book ID (integer) that this user read\n",
    "  * `comm_id`: The community ID to which the user belongs (integer)\n",
    "2. `rank` is an integer indicating how many of the top books we want to return. For instance, if `rank=5`, then we want results for just the top 5 books in each community.\n",
    "\n",
    "**Your task:** For each community, calculate what _percentage_ of its users read each book. That is, we would like to be able to see something like \"in Community 2, 25% of the users read book 238.\" We then want to identify the top `rank` books.\n",
    "\n",
    "There are several strategies for this exercise, but you might consider something along these lines.\n",
    "- Determine the number of unique users in each community. You need this information to get percentages.\n",
    "- Determine how many users read each book by community.\n",
    "- Normalize these counts by the community size.\n",
    "- Sort and return the results, retaining just the top `rank` books in each community.\n",
    "\n",
    "**Outputs:** Your function should return a new `DataFrame` with the following columns:\n",
    "- `comm_id`: The community ID\n",
    "- `book_id`: A book ID that was read in that community\n",
    "- `percent`: The percentage of the community that read that book.\n",
    "- `comm_size`: The number of users in the community\n",
    "\n",
    "As noted above, return **at most** the top `rank` books per community. In the event of ties, retain books with the lowest ID. (This choice is arbitrary but will simplify your implementation.)\n",
    "\n",
    "**Additional notes and hints:** If your code calculates a fraction, don't forget to multiply by 100 to get a percentage value for your final output.\n",
    "\n",
    "**Example:** Consider this input dataframe and a target rank of 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56382054",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:26.423969Z",
     "start_time": "2023-03-30T22:24:26.398428Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [],
   "source": [
    "### Define demo inputs ###\n",
    "\n",
    "demo_xcdf_ex8 = load_df_from_file('demo_ex8.df').reset_index(drop=True)\n",
    "demo_rank_ex8 = 2\n",
    "\n",
    "demo_xcdf_ex8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad2b9fb",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "From the demo input shown above, your function should return:\n",
    "\n",
    "|   comm_id |   book_id |   percent |   comm_size |\n",
    "|----------:|----------:|----------:|------------:|\n",
    "|         0 |       821 |   7.89474 |          38 |\n",
    "|         0 |       536 |   5.26316 |          38 |\n",
    "|         3 |       938 |  12.5     |          32 |\n",
    "|         3 |       943 |   9.375   |          32 |\n",
    "|         5 |      1386 |  12       |          25 |\n",
    "|         5 |      1473 |  12       |          25 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624bb0be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:26.457958Z",
     "start_time": "2023-03-30T22:24:26.424955Z"
    },
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [],
   "source": [
    "### Exercise 8 solution\n",
    "def get_topreads_by_community(xcdf, rank=5):\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "### demo function call ###\n",
    "get_topreads_by_community(demo_xcdf_ex8, demo_rank_ex8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76f212b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "**RUN ME:** If your function was working correctly, you would identify these top books by community on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de570920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:26.483680Z",
     "start_time": "2023-03-30T22:24:26.458994Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ex8_topreads = load_df_from_file('ex8-output.df')\n",
    "ex8_topreads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ae7f82",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 8. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7a7b63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:33.724342Z",
     "start_time": "2023-03-30T22:24:33.118868Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "ex8",
     "locked": true,
     "points": "3",
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### test_cell_ex8\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_8', \n",
    "    'func': get_topreads_by_community, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'xcdf': {\n",
    "            'dtype': 'df', # data type of param.\n",
    "            'check_modified': True,\n",
    "        },\n",
    "        'rank': {\n",
    "            'dtype': 'int',\n",
    "            'check_modified': False\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index': 0,\n",
    "            'dtype': 'df',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': False, # Ignored if dtype is not df\n",
    "            'check_row_order': False, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'jpS7W-CpqAQfuITMEQZL-yVXfhIaCkSaei-emnyRtrI=', path='')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "        \n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0b2698",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Part F (final part!): Merging inventory metadata #\n",
    "\n",
    "> Includes Exercises 9 and 10 (2 points each).\n",
    "\n",
    "\n",
    "To interpret the communities, we need to bring in some book-inventory metadata, like book titles and genres. Once we've done so, will the communities make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc12f38b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Genre vectors ##\n",
    "\n",
    "The original dataset includes information on _genres_ for each book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5567810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:33.895548Z",
     "start_time": "2023-03-30T22:24:33.725382Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "genres = pd.read_sql(\"SELECT * FROM Genres\", grdbconn)\n",
    "genres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562325d7",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "It's a bit messy, however: the genre information is stored as a JSON-formatted Python string encoding a **genre vector**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672e3717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:33.918656Z",
     "start_time": "2023-03-30T22:24:33.897585Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Inspect the very first genre entry:\n",
    "print(f\"* Type: `{type(genres['genres'].iloc[0])}`\")\n",
    "print(f\"* Value: '{genres['genres'].iloc[0]}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b160cd",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "This genre vector says that this particular book mixes three genres: `fiction`, `romance`, and `\"mystery, thriller, crime\"` (considered a single genre). Each value measures the relevance of that genre to the book.\n",
    "\n",
    "> Roughly speaking, let's interpret `555` as meaning this book is 555 / (555+23+10) ~ 94.3% \"fiction\" and 23 / (555+23+10) ~ 3.9% \"romance.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d77913",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The database stores these as genre vectors as strings. However, we can easily convert them to Python dictionaries using the following helper function, `from_json_str`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039cdf99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:33.941367Z",
     "start_time": "2023-03-30T22:24:33.919682Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def from_json_str(s):\n",
    "    \"\"\"Parses the JSON string `s` and returns a Python object.\"\"\"\n",
    "    from json import loads\n",
    "    return loads(s)\n",
    "\n",
    "\n",
    "# Demo #\n",
    "\n",
    "print(\"iloc 0:\", from_json_str(genres['genres'].iloc[0]))\n",
    "print(\"iloc 1:\", from_json_str(genres['genres'].iloc[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b194a25",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We will treat these as (mathematical) vectors that we can \"add.\" Here is a simple function to compute the sum of two genre vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c1e15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:33.966242Z",
     "start_time": "2023-03-30T22:24:33.942527Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def add_genre_vecs(x, y):\n",
    "    \"\"\"Returns the sum of two genre vectors.\"\"\"\n",
    "    from collections import defaultdict\n",
    "    z = defaultdict(int)\n",
    "    for k, v in x.items():\n",
    "        z[k] += v\n",
    "    for k, v in y.items():\n",
    "        z[k] += v\n",
    "    return dict(z) # Converts into a regular Python dict\n",
    "\n",
    "# Demo: start with two genre vectors, converted to `dict`:\n",
    "demo_genre_vec_a = from_json_str(genres['genres'].iloc[0])\n",
    "demo_genre_vec_b = from_json_str(genres['genres'].iloc[1])\n",
    "\n",
    "# Add them:\n",
    "add_genre_vecs(demo_genre_vec_a, demo_genre_vec_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c708a150",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## **Ex. 9 (2 pts)**: `merge_genre_vecs` ##\n",
    "\n",
    "Suppose you are given a pandas `Series` whose values are JSON strings encoding individual genre vectors. Complete the function,\n",
    "```python\n",
    "def merge_genre_vecs(series):\n",
    "    ...\n",
    "```\n",
    "so that it combines the genre vectors into a single, **normalized** genre vector.\n",
    "\n",
    "**Inputs:** The input is a `Series` object containing Python strings. Each string is a JSON-formatted genre vector.\n",
    "\n",
    "**Your task:**\n",
    "- Convert every JSON string into a Python dictionary. Use or adapt `from_json_str` from above.\n",
    "- Compute the \"sum\" of all these dictionaries. Use or adapt `add_genre_vecs` from above.\n",
    "\n",
    "The result of the previous two steps is a **single dictionary**. The final step is to _normalize_ this result. That is, divide each value of the result by the sum of all the values.\n",
    "\n",
    "**Outputs:** Your function should return the normalized genre vector as a Python dictionary.\n",
    "\n",
    "**Example:** Consider the following example input, a `Series` of JSON strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063f11cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:33.989138Z",
     "start_time": "2023-03-30T22:24:33.967376Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [],
   "source": [
    "### Define demo inputs ###\n",
    "\n",
    "demo_series_ex9 = pd.Series(\n",
    "    ['{\"fiction\": 555, \"romance\": 23, \"mystery, thriller, crime\": 10}',\n",
    "     '{\"non-fiction\": 534, \"history, historical fiction, biography\": 178, \"fiction\": 16, \"comics, graphic\": 6}',\n",
    "     '{\"non-fiction\": 163}',\n",
    "     '{\"fiction\": 425, \"history, historical fiction, biography\": 330, \"young-adult\": 93, \"children\": 190}',\n",
    "     '{\"fantasy, paranormal\": 1}'])\n",
    "\n",
    "print(demo_series_ex9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178898fd",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "A correct `merge_genre_vecs` implementation should return the dictionary,\n",
    "\n",
    "```python\n",
    "{'fiction': 0.39461172741679873,\n",
    " 'romance': 0.009112519809825673,\n",
    " 'mystery, thriller, crime': 0.003961965134706815,\n",
    " 'non-fiction': 0.27614896988906495,\n",
    " 'history, historical fiction, biography': 0.20126782884310618,\n",
    " 'comics, graphic': 0.002377179080824089,\n",
    " 'young-adult': 0.036846275752773376,\n",
    " 'children': 0.07527733755942947,\n",
    " 'fantasy, paranormal': 0.0003961965134706815}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d4574",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:34.013349Z",
     "start_time": "2023-03-30T22:24:33.990117Z"
    },
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [],
   "source": [
    "### Exercise 9 solution\n",
    "def merge_genre_vecs(series):\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "### demo function call ###\n",
    "merge_genre_vecs(demo_series_ex9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee32c18c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 9. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c8cd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:34.291949Z",
     "start_time": "2023-03-30T22:24:34.235510Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "ex9",
     "locked": true,
     "points": "2",
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### test_cell_ex9\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_9', \n",
    "    'func': merge_genre_vecs, # replace this with the function defined above\n",
    "    'inputs': { # input config dict. keys are parameter names\n",
    "        'series': {\n",
    "            'dtype':'series', # data type of param.\n",
    "            'check_modified':True,\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index': 0,\n",
    "            'dtype': 'dict',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': True, # Ignored if dtype is not df\n",
    "            'check_row_order': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'jpS7W-CpqAQfuITMEQZL-yVXfhIaCkSaei-emnyRtrI=', path='')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05fd74c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-30T22:24:41.967853Z",
     "start_time": "2023-03-30T22:24:41.946674Z"
    },
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "try:\n",
    "    grdbconn.close()\n",
    "except:\n",
    "    print(\"Goodreads database-connection may already be closed.\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2b38b6e01547e8f771d473ea2b8718fd0728eea782e4c924ed8783f739d4a6c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
